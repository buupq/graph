{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DODWCE_RBW_k"
   },
   "source": [
    "# GraphSAGE\n",
    "\n",
    "- References:\n",
    "> https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.SAGEConv.html\n",
    "> https://arxiv.org/abs/1706.02216\n",
    "- GraphSAGE is designed to handle large graphs.\n",
    "- There are three gradient descent algorithms:\n",
    "    - Batch gradient descent: update weight and bias after processing the entire dataset. This algorithm is accurate, but memory expensive.\n",
    "    - Stochastic gradient descent: update weight and bias for every training example. This algorithm is cheap, but high highly fluctuate.\n",
    "    - Mini-batch gradient descent: update weight and bias every n-training example. This algorithm is a balance between computational cost and accuracy and convergence.\n",
    "- Creating dataloader for mini-batch in graph can be tricky since it can break node connections, create isolated nodes. GraphSAGE divide graph dataset using neighbor sampling approach.\n",
    "***\n",
    "- In 1-layer GNN, only neighbors (1-hop) of a target node is needed. In 2-layer GNN, neighbors of the target node neighbors (2-hop) are needed.\n",
    "- There are 2 problems:\n",
    "    - Computational cost grows exponentially.\n",
    "    - Unbalance work for uneven node degree distribution.\n",
    "- These issues are solved by soing neighbor sampling and limit the number of neighbors for aggregation.\n",
    "***\n",
    "- There are three aggregators:\n",
    "    - Mean aggregator.\n",
    "    - Long-short term memory aggregator.\n",
    "    - Pooling aggregator.\n",
    "- The mean aggregator consists of the following steps:\n",
    "    - Averaging target node and its neighbor embeddings.\n",
    "    - Perform linear transformation and apply activation function\n",
    "> $h^\\prime_A = \\sigma(W . mean_{i\\in N_A}\\{h_i\\})$\n",
    "    - A variant of this method is to perform transformation for target node and neighbor separately:\n",
    "> $h^\\prime_A = \\sigma(W_1h_A + W_2 . mean_{i\\in N_A}\\{h_i\\})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pubmed dataset\n",
    "- Pubmed dataset is similar to Cora and CiteSeer that have:\n",
    "    - 19,717 articles (nodes)\n",
    "    - 88,648 references (edges)\n",
    "    - 500-dimension binary vector title (node features)\n",
    "- These articles belong to 3 categories:\n",
    "    - Mellitus experimental,\n",
    "    - Diabetes mellitus type 1\n",
    "    - Diabetes mellitus type 2\n",
    "- The target of node classification is to label articles to one of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import torch\n",
    "try:\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "except:\n",
    "    !pip install torch-geometric\n",
    "    from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# download Pubmed\n",
    "pubmed_dataset = Planetoid(root='.', name='Pubmed')\n",
    "pubmed_data = pubmed_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Pubmed articles with GraphSAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device agnostic\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import dataloader module\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "# create the train dataloader\n",
    "train_loader = NeighborLoader(\n",
    "    pubmed_data,\n",
    "    num_neighbors=[10,10],\n",
    "    batch_size=16,\n",
    "    input_nodes=pubmed_data.train_mask\n",
    ")\n",
    "\n",
    "# print a batch\n",
    "batch = next(iter(train_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create graphSAGE class\n",
    "from torch.nn import functional\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_in:int, dim_h:int, dim_out:int):\n",
    "        super().__init__()\n",
    "        self.sage1 = SAGEConv(in_channels=dim_in, out_channels=dim_h)\n",
    "        self.sage2 = SAGEConv(in_channels=dim_h, out_channels=dim_out)\n",
    "        \n",
    "    def forward(self, x:torch.Tensor, edge_index:torch.Tensor):\n",
    "        x = self.sage1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = functional.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.sage2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a GraphSAGE instance for Pubmed and send the model to device\n",
    "pubmed_model = GraphSAGE(\n",
    "    dim_in = pubmed_dataset.num_features,\n",
    "    dim_h = 64,\n",
    "    dim_out = pubmed_dataset.num_classes\n",
    ").to(device)\n",
    "pubmed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=pubmed_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train GraphSage on device\n",
    "from sources.revisited_engine import train_graph_sage\n",
    "\n",
    "results = train_graph_sage(\n",
    "    model=pubmed_model,\n",
    "    dataloader=train_loader,\n",
    "    device=device,\n",
    "    loss_fn = loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=101,\n",
    "    print_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# visualize results\n",
    "from sources.revisited_utils import visualize_results\n",
    "\n",
    "visualize_results(results=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute test accuracy\n",
    "from sources.revisited_engine import test\n",
    "\n",
    "test_acc = test(\n",
    "    model=pubmed_model.cpu(),\n",
    "    data=pubmed_data\n",
    ")\n",
    "print(f\"Test accuracy: {test_acc*100:.1f}(%)\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3556630122da5213751af4465d61fcf5a52cd22515d400aee51118aaa1721248"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
